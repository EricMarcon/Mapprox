---
title: "Traitement des données de grande taille avec M"
author:
  - name: "Eric Marcon"
    authsuperscript: "1*"
  - name: "Florence Puech"
    authsuperscript: "2"
affiliation:
  - affsuperscript: 1
    dptuniv: "AgroParisTech, UMR AMAP, CIRAD, CNRS, INRAE, IRD, Univ Montpellier, Montpellier, France."
  - affsuperscript: 2
    dptuniv: "Université Paris-Saclay, INRAE, AgroParisTech, Paris-Saclay Applied Economics, F-91120 Palaiseau, France"
corrauthor:
  email: eric.marcon@agroparistech.fr
abstract: >
  Cet article méthodologique porte sur une mesure relative de la concentration spatiale en espace continu, la fonction $M$, proposée par @Marcon2010.
  L'objectif de notre contribution est d'apporter des réponses au traitement de jeu de données spatialisées de grande taille avec M sous R. 
  Plus précisément, les deux sources d'incertitude pour le traitement de jeux de données importants sont analysées: les temps de calcul et l'estimation des erreurs liées à l'approximation de la position géographique des observations. 
  Dans un premier temps, les besoins en temps et en mémoire du calcul exact avec le package dbmss sous R sont évalués.
  Dans un second temps, nous testons l'impact de l'approximation de la position géographique sur la précision de M, comme proposé par @Tidu2023.
  Le code R est fourni pour la reproductibilité des résultats.
date: "`r format(Sys.time(), '%Y %B %d')`"
archive: "`r format(Sys.time(), '%d %B %Y')`"
url: https://EricMarcon.github.io/Mapprox/
github-repo: EricMarcon/Mapprox
# Language
lang: fr-FR
# Bibliography
bibliography: references.bib
biblio-style: chicago
# LaTeX
# Print table of contents in PDFs?
pdftoc: false
# If true, choose its depth
toc-depth: 3
# URL color
urlcolor: blue
# Do not modify
always_allow_html: yes
output:
  bookdown::html_document2:
    base_format: distill::distill_article
    toc: yes
    toc_float: yes
  bookdown::pdf_book:
    template: latex/template.tex
    citation_package: natbib
    latex_engine: xelatex
    keep_tex: no
---

```{r DoNotModify, include=FALSE}
### Utilities. Do not modify.
# Installation of packages if necessary
InstallPackages <- function(Packages) {
  InstallPackage <- function(Package) {
    if (!Package %in% installed.packages()[, 1]) {
      install.packages(Package, repos="https://cran.rstudio.com/")
    }
  }
  invisible(sapply(Packages, FUN = InstallPackage))
}

# Basic packages
InstallPackages(c("bookdown", "formatR", "ragg", "magick", "kableExtra"))

# Chunk font size hook: allows size='small' or any valid Latex font size in chunk options
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$size != "normalsize", paste0("\n \\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})
```

```{r Options, include=FALSE}
### Customized options for this document
# Add necessary packages here
Packages <- c("tidyverse", "spatstat", "dbmss", "pbapply", "plyr", "GoFKernel", "microbenchmark", "profmem")
# Install them
InstallPackages(Packages)

# knitr options
knitr::opts_chunk$set(
  cache =   TRUE,     # Cache chunk results
  include = TRUE,     # Show/Hide chunks
  echo =    TRUE,     # Show/Hide code
  warning = FALSE,    # Show/Hide warnings
  message = FALSE,    # Show/Hide messages
  # Figure alignment and size
  fig.align = 'center', out.width = '80%',
  # Graphic devices (ragg_png is better than standard png)
  dev = c("ragg_png", "pdf"),
  # Code chunk format
  tidy = FALSE, tidy.opts = list(blank=FALSE, width.cutoff=50),
  size = "scriptsize", knitr.graphics.auto_pdf = TRUE
  )
options(width = 50)

# ggplot style
library("tidyverse")
theme_set(theme_bw())
theme_update(panel.background=element_rect(fill="transparent", colour=NA),
             plot.background=element_rect(fill="transparent", colour=NA))
knitr::opts_chunk$set(dev.args=list(bg="transparent"))

# Random seed
set.seed(973)
```

# Motivation

L'accès grandissant à d'importants jeux de données individuelles et spatialisées et une plus grande puissance de calcul ont encouragé le développement d'outils d'analyse statistiques permettant de traiter au mieux de telles données [@Baddeley2016a]. 
Des études empiriques à des niveaux géographiques très fins ont ainsi pu été proposées au cours des dernières années pour des jeux de données de grande taille. 
Une attention particulière a porté sur la détection des structures spatiales (attraction, répulsion, indépendance) de données individuelles spatialisées à partir d'analyses ne reposant plus des données zonées mais sur des données géolocalisées. 
Ce type d'approche a l'avantage de préserver les positions exactes des entités analysées  et par conséquent de ne pas gommer les spécificités individuelles. 
Diverses études ont montré toute l'importance de retenir une telle méthodologie dans des domaines très variés comme en géographie [@Sweeney1998, @Deurloo2008], en économie [@Arbia1989, @Marcon2003a], en écologie [@Cressie1993,@Lentz2011],  en biologie [@Dray2021] etc.
Dans un article récent, @Tidu2023 soulignent l'intérêt d'une mesure statistique particulière, la fonction *M* proposée par @Marcon2010. 
Cette mesure, que nous dénommerons *M* dans la suite de l'article, permet de mettre en évidence et les structures spatiales au sein d'une distribution spatialisée (attraction, répulsion, indépendance) à partir d'une étude fondée sur les distances séparant les entités analysées. 
Toutefois, si cette mesure permet de préserver toute la richesse des données individuelles géolocalisées, elle nécessite un temps de calcul plus long que d'autres mesures fondées sur les distances puisqu'elle est à la fois une mesure cumulative et relative (voir @Marcon2012c pour une revue de littérature sur les avantages et les limites d'une dizaine mesures existantes fondées sur les distances). 
@Tidu2023 proposent de limiter les temps de calculs de *M* en introduisant une erreur de positionnement volontaire des entités analysées. 
Ainsi, dans leur étude, les établissements industriels en Sardaigne (Italie) ne sont plus localisés à leur adresse postale exacte mais au centroïde de leur municipalité. 
Ce repositionnement permet de réduire les temps de calcul car le nombre de distances possibles entre les établissements est, de fait, limité aux distances séparant les centroïdes des communes. 
Cette approche est analogue à celle de @Scholl2013 qui ont proposé, pour la fonction $K_d$ [@Duranton2005] qui permet de caractériser les structures spatiales par une autre méthode, d'approximer les distances entre paires d'entités en les regroupant par classes.
La méthode de @Scholl2013, implémentée dans le package *dbmss* [@Marcon2014] pour R [R] apporte un gain de performance computationnelle considérable avec une faible perte de précision.

Dans notre article, nous proposons de tester l'efficacité de la méthode de @Tidu2023.
Dans un premier temps, nous montrons les avantages de l'utilisation du package *dbmss* [@Marcon2014] pour estimer la fonction *M* sur des jeux de données dont l'ordre de grandeur est de 100000 points ou moins et nous montrons que les temps de calcul deviennent excessifs au delà.
Nous étudions ensuite l'effet de l'approximation géographique des localisations des entités analysées.
Ce travail méthodologique reposant sur un nombre d'emplacements des entités volontairement limité permet de quantifier l'importance de la détérioration de l'information que cette approche crée. 

Le plan de l'article est le suivant. 
Une première section génère les données nécessaires. 
Des jeux de points de grande taille (de l'ordre de plusieurs dizaines de milliers de points) complètement aléatoires ou (géographiquement) concentrés sont tirés. 
La deuxième section détaille l'utilisation du package *dbmss* pour calculer la fonction *M* et son intervalle de confiance à partir d'un tableau donnant la position et les caractéristiques des points ou bien une matrice de distances entre eux. 
La troisième section mesure la performance de *dbmss* en fonction de la taille du jeu de points, en termes de temps de calcul et de mémoire nécessaire.
Enfin, la dernière section teste l'approximation qui consiste à les rassembler au centre des cases d'une grille, selon l'approche de @Tidu2023 qui les positionnent au centre des unités administratives dans lesquelles ils se trouvent. 
 



# Simulation des données

Les jeux de données que nous allons considérer dans cet article sont obtenus par simulation. 
Le code R est donné en annexe, ce qui permet une parfaite reproductibilité les exemples traités ou d'en développer d'autres.

## Tirage des points

Un jeu de points est tiré par un processus binomial dans une fenêtre carrée de côté 1. 
On associe à chaque point une marque qualitative: "Cas" ou "Contrôle". 
La majorité des points sont des "Contrôles" et une partie constitue des "Cas", dont la structure spatiale est étudiée. 
Le poids des points est tiré dans une loi gamma dont les paramètres de forme et d'échelle sont libres.

```{r}
#| label: ParamsCSR
#| include: false
#| ref.label: ParamsCSRCode
```

```{r}
#| label: XCSR
#| include: false
#| ref.label: XcsrCode
```

Dans cet exemple, le tirage des points est complètement aléatoire (*complete spatial randomness*: CSR), c'est-à-dire qu'il n'y a pas ici de simulation d'attraction ou de dispersion de points qui pourraient générer des concentrations spatiales de points (agrégats) ou, au contraire, des régularités spatiales (dispersions).

Des jeux de points agrégés peuvent être tirés dans un processus de @Matern1960.

```{r}
#| label: ParamsMatern
#| include: false
#| ref.label: ParamsMaternCode
```

(ref:XMatern) Tirage d'un jeu de points dont les cas (en rouge) sont agrégés alors que les contrôles (en bleu) sont distribués complèteent aléatoirement. La taille des points est proportionnelle à leur poids. 

```{r}
#| label: XMaternFig
#| echo: false
#| ref.label: XMaternCode
#| fig.cap: "(ref:XMatern)"
```

Les Cas apparaissent dans figure \@ref(fig:XMaternFig): les agrégats sont nettement visibles.
Les contrôles (non représentés) sont distribués complètement aléatoirement.


## Maillage de l'espace

Considérons la simulation des Cas obtenus par le processus de Matérn et découpons la fenêtre en une grille. 
Un maillage est de l'espace précédemment considéré est obtenu, qui permet de simuler l'approximation habituelle de la position des points d'une unité administrative sur la position de son centre.

```{r}
#| label: ParamsPartitions
#| include: false
#| ref.label: ParamsPartitionsCode
```

```{r}
#| label: group_points
#| include: false
#| ref.label: group_pointsCode
```

La position recentrée est présentée sur la carte de la figure \@ref(fig:GroupedFig).
Chaque cellule ne contient plus qu'un seul point de chaque type dont le poids est la somme des poids des points individuels.

(ref:Grouped) Repositionnement des points dans une grille arbitraire. L'absence de Cas dans une cellule est aisément détectable (point unicolore bleu), tout comme la forte présence de Cas dans une cellule (point bicolore mais à dominante rouge).

```{r}
#| label: GroupedFig
#| echo: false
#| ref.label: GroupedCode
#| fig.cap: "(ref:Grouped)"
```

Les valeurs de la fonction *M* peuvent maintenant être calculées à partir du jeu de point original ou de son approximation après recentrage. 


# Calcul de M avec le package *dbmss*

```{r}
#| label: Paramsr
#| include: false
#| ref.label: ParamsrCode
```

## Données nécessaires

Dans le package *dbmss*, la fonction s'applique à un jeu de points ou à une matrice de distance.
Le jeu de points de la figure \@ref(fig:XMaternFig) est utilisé.
La matrice de distances entre toutes les paires de ses points est calculée pour constituer les données sur lesquelles les tests de performance seront réalisés.

```{r}
#| label: DtableM
#| include: false
#| ref.label: DtableMCode
```

## Jeu de points

La fonction `Mhat()` du package *dbmss* permet d'estimer la fonction *M*.
La valeur de référence théorique de *M* est 1 car cette fonction rapporte la proportion de Cas jusqu'à une distance $r$ à celle observée sur toute la fenêtre. 
L'agrégation des Cas sera mise en évidence par des valeurs de *M* supérieures à 1 (la présence relative de Cas est plus importante localement que sur l'ensemble de la fenêtre) et la dispersion des Cas par des valeurs inférieures à 1. 
On observe (figure \@ref(fig:MFig)) que *M* détecte une agglomération des Cas, ce qui est en accord avec la simulation de ce type de points (les contrôles ayant localisation complètement aléatoire sur la fenêtre). 
L'avantage d'une fonction fondée sur les distances est nettement visible: elle permet de détecter exactement à quelle(s) distance(s) les phénomènes d'attraction se produisent et sont les plus importants (pour les fonctions dont les valeurs peuvent être comparées à différents rayons, comme *M*).

La fonction `Menvelope()` permet de calculer en plus de l'estimation de la fonction *M* son intervalle de confiance global [@Duranton2005] sous l'hypothèse nulle de localisation aléatoire des points.
Son résultat est représenté sur la figure \@ref(fig:MFig).

(ref:M) Valeur de *M* en fonction de la distance au point de référence. l'intervalle de confiance, simulé à 95%, apparaît en gris et est centré sur la valeur 1.

```{r}
#| label: MFig
#| echo: false
#| ref.label: MCode
#| fig.cap: "(ref:M)"
```


## Matrice de distances

```{r}
#| label: Dtable
#| include: false
#| ref.label: DtableCode
```

Les matrices permettent de traiter des distances non euclidiennes (temps de transport, distance routière...) qui ne peuvent pas être représentées par un jeu de points.

Les fonctions `Mhat()` et `MEnvelope()` sont les mêmes, et fournissent les mêmes résultats quelle que soit la forme des données utilisées ici (jeu de point ou matrice de distance).


# Performance du calcul

L'utilisation de la fonction *M* pour caractériser la structure spatiale de grands jeux de points peut être limitée par le temps de calcul ou la mémoire nécessaire.

```{r}
#| label: XtoM
#| include: false
#| ref.label: XtoMCode
```

## Temps de calcul

Le calcul des distances entre toutes les paires de points est nécessaire pour estimer *M*.
On s'attend donc à ce que le temps de calcul augmente comme le carré du nombre de points.

Le temps de calcul nécessaire au calcul exact est évalué pour une gamme de nombres de points (figure \@ref(fig:TestTimeFig)).

```{r}
#| label: ParamsXSize
#| include: false
#| ref.label: ParamsXSizeCode
```

(ref:TestTime) Temps de calcul de l'estimation de la fonction *M* en fonction de la taille du jeu de points. Les barres représentent l'intervalle de $\pm 1$ écart-type.

```{r}
#| label: TestTimeFig
#| echo: false
#| ref.label: TestTimeCode
#| fig.cap: "(ref:TestTime)"
```


Le temps de calcul est lié à la taille du jeu de points par une loi puissance.

```{r}
#| label: TimeModel
#| include: false
#| ref.label: TimeModelCode
```

Il augmente moins vite que le carré du nombre de points.
Il peut être estimé très précisément ($R^2=$ `r format(summary(M_time_lm)$r.squared, digits=2)`) par la relation $t = t_0 (n / n_o)^p$ où $t$ est le temps estimé pour $n$ points connaissant le temps $t_0$ (ex.: `r format(as.numeric(M_time[5, 2]), digits=3)` secondes) pour $n_0$ points (ex.: `r as.integer(M_time[5, 1])`) et $p$ la relation de puissance (`r format(M_time_lm$coefficients[2], digits=3)`).

L'utilisation d'une matrice de distance peut sembler efficace pour en économiser le temps de calcul mais le calcul des distances est en réalité extrêmement rapide et le traitement complet à partir d'une matrice est finalement plus long (tableau \@ref(tab:MmbTab)).

```{r}
#| label: Mmb
#| include: false
#| ref.label: MmbCode
```


```{r}
#| label: MmbTab
#| echo: false
mb |> summary() |> as.data.frame() |>
  select(expr, median) |> 
  mutate(
    `Méthode` = c("Jeu de points", "Matrice de distances"), 
    `Temps` = round(median),
    .before = expr,
    .keep = "none" 
  ) |>
  knitr::kable(
    caption = paste(
      "Temps d'exécution médian, en millisecondes, de l'estimation", 
      "de la fonction *M* à partir d'un jeu de",
      par_points_nb,
      "points ou de la matrice de distances correspondante"
    ),
    longtable = FALSE, 
    booktabs = TRUE
  ) %>%
  kableExtra::kable_styling(bootstrap_options = "striped", full_width = TRUE)
```


## Mémoire

La mémoire utilisée est évaluée pour les mêmes tailles de données (figure \@ref(fig:TestMemFig)).

(ref:TestMem) Mémoire nécessaire (Mo) pour l'estimation de la fonction *M* en fonction de la taille du jeu de points.

```{r}
#| label: TestMemFig
#| echo: false
#| ref.label: TestMemCode
#| fig.cap: "(ref:TestMem)"
```

La mémoire nécessaire augmente linéairement avec le nombre de points et n'est jamais critique pour des tailles de jeux de points traitables dans des temps raisonnables.
Cela permet de relativiser la conclusion de @Tidu2023 sur la puissance et le temps de calculs nécessaires en utilisant *M* sur des jeux de données de taille importante.

La mémoire utilisée par les objets `Dtable` pour le calcul de $M$ à partir d'une matrice de distance est bien supérieure: c'est celle d'une matrice numérique, de l'ordre de 8 octets fois le nombre de points au carré, soit 800 Mo pour 10000 points seulement.
Comme le temps de calcul n'est pas réduit par cette approche, son utilisation est à réserver aux distances non-euclidiennes.



# Effets de l'approximation de la position des points

```{r}
#| label: ParamsSims
#| include: false
#| ref.label: ParamsSimsCode
```

Il est évident que l'approximation de la position des points entraîne une perte d'information: dans chaque cellule de la grille, la distance entre tous les points est fixée à 0,et la distance entre deux points de cellules différentes est approchée par celle entre les centroïdes des deux cellules.
On s'attend donc à une sévère erreur dans l'estimation de *M* à petite échelle (de l'ordre de grandeur des la taille des cellules) et une erreur diminuant avec la distance, quand la taille relative des cellules diminue.

L'effet de l'approximation de la localisation est testé d'abord sur un jeu de points agrégé, similaire aux données réelles de @Tidu2023.
Dans un deuxième temps, le cas d'un jeu de points non structuré est traité.

## Cas d'une distribution agrégée (Matérn)

```{r}
#| label: XMaternList
#| include: false
#| ref.label: XMaternListCode
```

`r simulations_n` jeux de points agrégés sont simulés.
Pour évaluer l'effet de l'approximation de la position, le calcul exact et le calcul sur les points de la grille sont effectués sur chaque jeu de points.

```{r}
#| label: MMaternTime
#| include: false
#| ref.label: MMaternTimeCode
```

Les valeurs moyennes des estimations de *M* sont présentées dans la figure \@ref(fig:MapproxMaternFig).

(ref:MapproxMatern) Estimation moyenne de la fonction *M* à partir de la position exacte des points comparée aux valeurs obtenues en regroupant les points.

```{r}
#| label: MapproxMaternFig
#| echo: false
#| ref.label: MapproxMaternCode
#| fig.cap: "(ref:MapproxMatern)"
```

La taille des cellules de la grille est égale à `r 1/par_partitions`.
Tous les voisins à distance inférieure à ce seuil sont placés à distance nulle: l'estimation de la fonction est constante jusqu'à ce seuil.

La corrélation entre les valeurs de $M$ estimées par chaque méthode est calculée à chaque distance (figure \@ref(fig:CorMaternFig)).

(ref:CorMatern) Corrélation entre les valeurs de *M* estimées à partir de la position exacte des points et en regroupant les points.

```{r}
#| label: CorMaternFig
#| echo: false
#| ref.label: CorMaternCode
#| fig.cap: "(ref:CorMatern)"
```

La corrélation est très proche de 1, et les valeurs estimées très similaires, dès que la distance prise en compte dépasse la maille de la grille: l'approximation n'est pas un problème si les interactions entre les points sont étudiées au-delà de cette distance.
L'information sur les interactions à courte distance, c'est-à-dire à l'intérieur de chaque cellule de la grille, est perdue, ou, plus précisément, approximée par sa valeur à 
l'échelle de la grille.


## Cas d'une distribution complètement aléatoire (CSR)

```{r}
#| label: XCSRList
#| include: false
#| ref.label: XCSRListCode
```

Les mêmes simulations sont effectuées avec un jeu de points complètement aléatoire.
Le calcul exact et le calcul sur les points de la grille sont effectués sur chaque jeu de points.

```{r}
#| label: MCSRTime
#| include: false
#| ref.label: MCSRTimeCode
```

Les valeurs moyennes sont présentées dans la figure \@ref(fig:MapproxCSRFig).

(ref:MapproxCSR) Estimation moyenne de la fonction *M* à partir de la position exacte des points comparée aux valeurs obtenues en regroupant les points.

```{r}
#| label: MapproxCSRFig
#| echo: false
#| ref.label: MapproxCSRCode
#| fig.cap: "(ref:MapproxCSR)"
```

(ref:CorCSR) Corrélation entre les valeurs de *M* estimées à partir de la position exacte des points et en regroupant les points.

```{r}
#| label: CorCSRFig
#| echo: false
#| ref.label: CorCSRCode
#| fig.cap: "(ref:CorCSR)"
```

La valeur moyenne de $M$ est égale à 1 à toutes les distances par construction: les cas et les contrôles sont distribués complètement aléatoirement.
Les approximations sont relativement faibles en valeur (quelques pourcents) mais comme la valeur réelle de $M$ varie peu autour de 1, les corrélations sont bien plus faibles (figure \@ref(fig:CorCSRFig)) en absence de structure spatiale.


# Conclusion

Le temps de calcul de $M$ est de l'ordre de 6 secondes pour un jeu de 100 000 points sur un ordinateur portable (processeur Intel i7-1360P 2.20 GHz), et nécessite 25 Mo de RAM.
Le calcul d'un intervalle de confiance à partir de 1000 simulations prend donc moins de deux heures.

Pour un jeu de cinq millions de points, le temps de calcul attendu est $6 \times 50^{1.8} = 6860$ secondes, près de deux heures.
1000 simulations nécessiteraient alors environ trois mois.
Le calcul des distances est parallélisé: un serveur de calcul augmenterait drastiquement la performance mais au prix d'une complexité de mise en oeuvre qui limite son usage.

En se limitant à la puissance de calcul d'un ordinateur personnel, le calcul exact se justifie donc pleinement pour des données de l'ordre de $10^5$ points: quelques heures suffisent à calculer des intervalles de confiance.

Au-delà, l'approximation de la localisation permet de ramener la taille du jeu de points à celle du nombre de localisations retenues.
Le prix à payer est l'absence d'information à l'échelle des unités géographiques élémentaires (les cellules de la grille ici).
Selon les questions traitées, cette limite peut être acceptable ou non: la description globale de la structure spatiale est assez peu dégradée, mais l'étude des externalités, particulièrement intéressante à petite distance, est très limitée.


# Annexe

Le code utilisé dans cet article est détaillé ici.

## Simulation des données

### Tirage des points

```{r}
#| label: seed
#| echo: off
# Random seed, identical to that of the text
set.seed(973)
```

Un jeu de points est tiré aléatoirement avec les paramètres suivants:

-   le nombre de points,
-   la proportion de contrôles,
-   la forme et l'échelle de la loi gamma.

```{r}
#| label: ParamsCSRCode
library("tidyverse")
library("spatstat")
library("dbmss")

par_points_nb <- 5000
par_case_ratio <- 1/20
par_size_gamma_shape <- 0.95
par_size_gamma_scale  <- 10
```

La fonction `X_csr()` permet de tirer un semis de points selon des paramètres déterminés.
L'argument `points_nb` qui fixe le nombre de points peut être modifié; les autres paramètres ont leur valeur fixée plus haut.

```{r}
#| label: XcsrCode
X_csr <- function(
    points_nb,
    case_ratio = par_case_ratio,
    size_gamma_shape = par_size_gamma_shape,
    size_gamma_scale = par_size_gamma_scale) {
  points_nb %>% 
    runifpoint() %>% 
    as.wmppp() ->
    X
  cases_nb <- round(points_nb *  case_ratio)
  controls_nb <- points_nb - cases_nb
  c(rep("Control", controls_nb), rep("Case", cases_nb)) %>% 
    as.factor() ->
    X$marks$PointType
  rgamma(
    X$n, 
    shape = size_gamma_shape, 
    scale = size_gamma_scale
  ) %>% 
    ceiling() ->
    X$marks$PointWeight
  X
}

# Example
X <- X_csr(par_points_nb)
# Map the cases
autoplot(X[X$marks$PointType == "Case"])
```


La distribution des tailles est donnée par l'histogramme suivant:

```{r}
#| label: PointSizeCode
# Point size distribution
hist(
  X$marks$PointWeight, 
  breaks = unique(X$marks$PointWeight), 
  main = "",
  xlab = "Point size"
)
```

La fonction `X_matern()` permet de tirer un semis de points dont les Cas sont concentrés par un processus de @Matern1960.
Les paramètres sont:

-   $\kappa$: le nombre d'agrégats attendu,
-   `scale`: leur rayon.

```{r}
#| label: ParamsMaternCode
# Expected number of clusters
par_kappa <- 20
# Cluster radius
par_scale <-  0.1
```

Le code de la fonction est le suivant:

```{r}
#| label: XMaternCode
X_matern <- function(
    points_nb,
    case_ratio = par_case_ratio,
    kappa = par_kappa,
    scale = par_scale,
    size_gamma_shape = par_size_gamma_shape,
    size_gamma_scale = par_size_gamma_scale) {
  cases_nb <- round(points_nb *  case_ratio)
  controls_nb <- points_nb - cases_nb
  # CSR controls
  controls_nb %>% 
    runifpoint() %>% 
    superimpose(
      # Matern cases
      rMatClust(
        kappa = kappa, 
        scale = scale, 
        mu = cases_nb / kappa
      ) 
    ) %>% 
    as.wmppp() ->
    X
  # Update the number of cases
  cases_nb <- X$n - controls_nb
  c(rep("Control", controls_nb), rep("Case", cases_nb)) %>% 
    as.factor() ->
    X$marks$PointType
  rgamma(
    X$n, 
    shape = size_gamma_shape, 
    scale = size_gamma_scale
  ) %>% 
    ceiling() ->
    X$marks$PointWeight
  X
}

# Example
X <- X_matern(par_points_nb)
# Map the cases
autoplot(X) + 
  scale_size(range = c(0, 3))
```


### Maillage de l'espace

Le nombre de lignes et de colonnes est paramétré:

```{r}
#| label: ParamsPartitionsCode
# Number of rows and columns
par_partitions <- 20
```

La fonction `group_points()` rassemble au centre de chaque cellule de la grille tous les points qu'elle contient.
Cela permet de simuler l'approximation habituelle de la position des points d'une unité administrative sur la position de son centre.
La position des points est légèrement bruitée pour permettre le calcul de M.
La fonction `group_points_to_plot()` fusionne les points pour produire une carte.

```{r}
#| label: group_pointsCode
# Group points into cells
group_points <- function(X, partitions = par_partitions) {
  X %>%
    with(tibble(
      x, 
      y, 
      PointType = marks$PointType, 
      PointWeight = marks$PointWeight)
    ) %>% 
    mutate(
      x_cell = ceiling(x * partitions) / partitions - 1 / 2 / partitions,
      y_cell = ceiling(y * partitions) / partitions - 1 / 2 / partitions,
      .keep = "unused"
    ) %>%
    rename(x = x_cell, y = y_cell) |> 
    as.wmppp(window = X$window, unitname = X$window$units) |> 
    rjitter()
}
# Group points and merge them
group_points_to_plot <- function(X, partitions = par_partitions) {
  X %>%
    with(tibble(
      x, 
      y, 
      PointType = marks$PointType, 
      PointWeight = marks$PointWeight)
    ) %>% 
    mutate(
      x_cell = ceiling(x * partitions) / partitions - 1 / 2 / partitions,
      y_cell = ceiling(y * partitions) / partitions - 1 / 2 / partitions
    ) %>%
    group_by(PointType, x_cell, y_cell) %>% 
    summarise(n = n(), PointWeight = sum(PointWeight)) %>% 
    rename(x = x_cell, y = y_cell) |> 
    as.wmppp(window = X$window, unitname = X$window$units)
}
```

La figure est obtenue par le code suivant:
```{r}
#| label: GroupedCode
X |> group_points_to_plot() |> autoplot(alpha = 0.5)
```


## Calcul de M

Les distances auxquelles la fonction *M* est calculées sont choisies dans `r`.

```{r}
#| label: ParamsrCode
r <- c((0:9) / 100, (2:10) / 20)
```

### Données nécessaires

Dans le package *dbmss*, la fonction s'applique à un jeu de points, objet de classe `wmppp`, ou à une matrice de distance, objet de classe `Dtable`.

Nous partons d'un tableau (data.frame) contenant les colonnes `x`, `y`, `PointType` et `PointWeight`.

Les coordonnées spatiales des points sont données par les colonnes `x` et `y`. 

```{r}
#| label: DtableMCode
# Extract a dataframe from the point set
points_df <- with(X, data.frame(x, y, marks))
head(points_df)
```

### Jeu de points

La fonction `Mhat()` permet d'estimer la valeur de la fonction *M*.

```{r}
#| label: Mhat
X %>% 
  Mhat(r = r, ReferenceType = "Case") %>% 
  autoplot()
```

La fonction `Menvelope()` permet de calculer l'intervalle de confiance de la valeur de la fonction sous l'hypothèse nulle de localisation aléatoire des points.
L'intervalle de confiance global [@Duranton2005] est calculé en précisant l'argument `Global = TRUE`.

```{r}
#| label: MCode
X %>% 
  MEnvelope(r = r, ReferenceType = "Case", Global = TRUE) %>% 
  autoplot()
```

### Matrice de distances

La fonction `as.Dtable()` permet de créer un objet `Dtable`.

```{r}
#| label: DtableCode
d_matrix <- as.Dtable(points_df)
```

Il peut aussi être créé à partir d'une matrice de distances obtenue autrement, contenant par exemple des distances non euclidiennes (temps de transport, distance routière...).

```{r}
#| label: Dtable2
#| eval: true
# A Dtable containing two points
Dmatrix <- matrix(c(0, 1, 1, 0), nrow = 2)
PointType <- c("Type1", "Type2")
PointWeight <- c(2, 3)
Dtable(Dmatrix, PointType, PointWeight)
```

Les fonctions `Mhat()` et `MEnvelope()` sont les mêmes que pour les jeux de points.

```{r}
#| label: Mid
#| eval: true
identical(
  Mhat(X, r = r, ReferenceType = "Case", NeighborType = "Control"),
  Mhat(d_matrix, r = r, ReferenceType = "Case", NeighborType = "Control")
)
```

```{r}
#| label: MEnvelopeid
#| eval: true
d_matrix %>% 
  MEnvelope(r = r, ReferenceType = "Case", Global = TRUE) %>% 
  autoplot()
```



## Performance de M

La fonction `X_to_M()` calcule la fonction $M$ et renvoie le vecteur de ses valeurs pour chaque distance.
Elle est utile pour mesurer les temps d'exécution.

```{r}
#| label: XtoMCode
# Compute M
X_to_M <- function(X) {
  X %>% 
    Mhat(r = r, ReferenceType = "Case") %>% 
    pull("M")    
}
```

### Temps de calcul

Le temps nécessaire au calcul exact est évalué pour une gamme de nombres de points précisée dans `X_sizes`.

```{r}
#| label: ParamsXSizeCode
X_sizes <- c(1000, 5000, 10000, 50000, 100000)
```

La fonction `test_time()` permet de mesurer le temps d'exécution d'une évaluation de la fonction $M$.

```{r}
#| label: TestTimeCode
library("microbenchmark")
test_time <- function(points_nb) {
  X <- X_csr(points_nb)
  microbenchmark(X_to_M(X), times = 4L) %>% 
    pull("time")
}

X_sizes %>% 
  sapply(FUN = test_time) %>% 
  as_tibble() %>% 
  pivot_longer(cols = everything()) %>% 
  rename(Size = name) %>% 
  group_by(Size) %>% 
  summarise(Time = mean(value) / 1E9, sd = sd(value) / 1E9) %>% 
  mutate(
    Size = as.double(
      plyr::mapvalues(
        .$Size, 
        from = paste0("V", seq_along(X_sizes)), 
        to = X_sizes
      )
    )
  ) -> M_time
M_time %>% 
  ggplot(aes(x = Size, y = Time)) +
    geom_point() +
    geom_errorbar(aes(ymin = Time - sd, ymax = Time + sd)) +
    scale_x_log10() +
    scale_y_log10()
```

Le temps de calcul est lié à la taille du jeu de points par une loi puissance.

```{r}
#| label: TimeModelCode
# Model
M_time %>% 
  mutate(logTime = log(Time), logSize = log(Size)) ->
  M_time_log
M_time_lm <- lm(logTime ~ logSize, data = M_time_log) 
summary(M_time_lm)
```


Le package *microbenchmark* proposé par @Mersmann2023 est retenu pour comparer le temps de calcul de la fonction entre un jeu de points et une matrice de distances.

Le calcul des distances est extrêmement rapide dans la fonction `Mhat()`: la matrice le fait économiser, mais le traitement complet à partir d'une matrice est finalement plus long.

```{r}
#| label: MmbCode
#| eval: true
library("microbenchmark")
mb <- microbenchmark(
  Mhat(X, r = r, ReferenceType = "Case", NeighborType = "Control"),
  Mhat(d_matrix, r = r, ReferenceType = "Case", NeighborType = "Control"),
  times = 4L
)
```


### Mémoire

La mémoire utilisée est évaluée avec le package *profmem*.

```{r}
#| label: TestMemCode
# RAM
library("profmem")
test_ram <- function(points_nb) {
  X <- X_csr(points_nb)
  profmem(X_to_M(X)) %>% 
    pull("bytes") %>% 
    sum(na.rm = TRUE)
}
sapply(X_sizes, FUN = test_ram) %>% 
  tibble(Size = X_sizes, RAM = . / 2^20) ->
  M_ram
M_ram %>% 
  ggplot(aes(x = Size, y = RAM)) +
    geom_point() +
    geom_line()
```

La mémoire nécessaire (en Mo) augmente linéairement avec le nombre de points.

```{r}
#| label: MemModelCode
# Model
lm(RAM ~ Size, data = M_ram) |> summary()
```


## Effets de l'approximation de la position des points

Le nombre de répétition des tests est fixé par `simulations_n`.

```{r}
#| label: ParamsSimsCode
simulations_n <- 100
```


### Cas d'une distribution agrégée (Matérn)

`X_matern_list` contient `simulations_n` tirages du jeu de points.
`X_matern_grouped_list` contient les mêmes simulations, dont les points ont été regroupés dans les cases de la grille.

```{r}
#| label: XMaternListCode
# Simulate X
X_matern_list <- replicate(
  simulations_n, 
  expr = X_matern(par_points_nb), 
  simplify = FALSE
)
# Group points and compute M
X_matern_grouped_list <- lapply(
  X_matern_list, 
  FUN = group_points, 
  partitions = par_partitions
)
```

Pour évaluer l'effet de l'approximation de la position, le calcul exact et le calcul sur les points de la grille sont effectués sur chaque jeu de points.

```{r}
#| label: MMaternTimeCode
#| eval: true
library("pbapply")
# Compute M
M_matern_original <- pbsapply(X_matern_list, FUN = X_to_M)
M_matern_grouped <- pbsapply(X_matern_grouped_list, FUN = X_to_M)
```

Le calcul approximé est très rapide parce qu'il réduit le nombre de points à celui du nombre de cellules, à condition d'en tirer partie dans le code utilisé pour le calcul.
Ce n'est pas le cas ici: le package *dbmss* ne prévoit pas cette approximation.
La fonction `M_hat()` est donc appliquée au jeu de points regroupé mais calculée de la même façon qu'avec le jeu de points original.

Les valeurs moyennes des estimations de *M* sont présentées ci-dessous.

```{r}
#| label: MapproxMaternCode
#| eval: true
tibble(
  r,
  Original = rowMeans(M_matern_original), 
  Grouped =  rowMeans(M_matern_grouped)
) %>% 
  pivot_longer(
    cols = !r,
    names_to = "M", 
    values_to = "value"
  ) %>% 
  ggplot(aes(x = r, y = value, color = M)) +
  geom_line() +
  geom_point()
```

La corrélation entre les valeurs de $M$ estimées par chaque méthode est calculée à chaque distance.

```{r}
#| label: CorMaternCode
#| eval: true
# Correlation
M_cor <- function(r_value, M_original, M_grouped) {
  r_index <- which(r == r_value)
  # Return
  c(
    # Distance
    r_value,
    # Correlation
    cor(M_original[r_index, ], M_grouped[r_index, ])
  ) 
}
sapply(
  r, 
  FUN = M_cor, 
  M_original = M_matern_original, 
  M_grouped = M_matern_grouped
) %>%
  t() %>% 
  as_tibble() %>% 
  rename(r = V1, correlation = V2) %>% 
  ggplot(aes(x = r, y = correlation)) +
    geom_point() +
    geom_line()
```

La corrélation est très élevée dès que la distance prise en compte dépasse la maille de la grille.
Les valeurs sont ensuite comparées.

```{r}
#| label: CompMaternCode
#| eval: true
# Compare values
M_bias <- function(r_value, M_original, M_grouped) {
  r_index <- which(r == r_value)
  # Return
  c(
    # Distance
    r_value,
    # Relative error
    mean((M_grouped[r_index, ] - M_original[r_index, ]) / M_original[r_index, ]),
    # Standardised error sd
    sd(M_grouped[r_index, ] - M_original[r_index, ]) / mean(M_grouped[r_index, ]), 
    # Coefficient of variation
    sd(M_original[r_index, ] / mean(M_original[r_index, ]))
  )
}
sapply(
  r, 
  FUN = M_bias, 
  M_original = M_matern_original, 
  M_grouped = M_matern_grouped
) %>% 
  t() %>% 
  as_tibble() %>% 
  rename(r = V1, `Relative error` = V2, `Error CV` = V3, `M CV` = V4) %>% 
  ggplot() +
    geom_point(aes(x = r, y = `Relative error`)) +
    geom_errorbar(
      aes(
        x = r, 
        ymin = `Relative error` - `Error CV`, 
        ymax = `Relative error` + `Error CV`
      )
    ) +
    geom_errorbar(aes(x = r, ymin = -`M CV`, ymax = `M CV`), col = "red")
```

La figure ci-dessus montre, en rouge, la variabilité de la valeur de $M$ (son coefficient de variation) au cours des simulations.
Par définition, la valeur moyenne est sans erreur.
A courte distance, les valeurs de *M* varient beaucoup pour un même processus ponctuel, en fonction de la stochasticité de ses tirages.
Comme *M* est une fonction cumulative, elle se stabilise quand la distance augmente.

L'erreur relative (à la valeur exacte de $M$) moyenne, due à l'approximtion de la position des points, est présentée en noir, avec son écart-type normalisé par la valeur exacte de $M$.
Elle est faible, inférieure à 10%, même à courte distance.


### Cas d'une distribution complètement aléatoire (CSR)

`X_csr_list` contient `simulations_n` tirages du jeu de points.

```{r}
#| label: XCSRListCode
# Simulate X
X_csr_list <- replicate(
  simulations_n, 
  expr = X_csr(par_points_nb), 
  simplify = FALSE
)
# Group points and compute M
X_csr_grouped_list <- lapply(
  X_csr_list, 
  FUN = group_points, 
  partitions = par_partitions
)
```

Le calcul exact et le calcul sur les points de la grille sont effectués sur chaque jeu de points.

```{r}
#| label: MCSRTimeCode
#| eval: true
# Compute M
system.time(M_csr_original <- pbsapply(X_csr_list, FUN = X_to_M))
system.time(M_csr_grouped <- sapply(X_csr_grouped_list, FUN = X_to_M))
```

Les valeurs moyennes sont présentées ci-dessous.

```{r}
#| label: MapproxCSRCode
#| eval: true
tibble(
  r,
  Original = rowMeans(M_csr_original), 
  Grouped =  rowMeans(M_csr_grouped)
) %>% 
  pivot_longer(
    cols = !r,
    names_to = "M", 
    values_to = "value"
  ) %>% 
  ggplot(aes(x = r, y = value, color = M)) +
  geom_line() +
  geom_point()
```

La corrélation entre les valeurs de $M$ calculées par chaque méthode est calculée à chaque distance.

```{r}
#| label: CorCSRCode
#| eval: true
# Correlation
sapply(
  r, 
  FUN = M_cor, 
  M_original = M_csr_original, 
  M_grouped = M_csr_grouped
) %>%
  t() %>% 
  as_tibble() %>% 
  rename(r = V1, correlation = V2) %>% 
  ggplot(aes(x = r, y = correlation)) +
    geom_point() +
    geom_line()
```

En absence de structure spatiale, les corrélations sont bien plus faibles.

Les valeurs sont comparées.

```{r}
#| label: CompCSRCode
#| eval: true
# Compare values
sapply(
  r, FUN = M_bias, 
  M_original = M_csr_original, 
  M_grouped = M_csr_grouped
) %>% 
  t() %>% 
  as_tibble() %>% 
  rename(r = V1, `Relative error` = V2, `Error CV` = V3, `M CV` = V4) %>% 
  ggplot() +
    geom_point(aes(x = r, y = `Relative error`)) +
    geom_errorbar(
      aes(
        x = r, 
        ymin = `Relative error` - `Error CV`, 
        ymax = `Relative error` + `Error CV`
      )
    ) +
    geom_errorbar(aes(x = r, ymin = -`M CV`, ymax = `M CV`), col = "red")
```


La figure ci-dessus est construite de la même façon que pour les jeux de points agrégés.
En absence de structure spatiale, la valeur de *M* varie beaucoup moins.

En présence d'une structure spatiale, l'erreur d'estimation est grande à courte distance.
Elle devient négligeable au-delà de la maille de la grille.
