---
title: "Traitement des données de grande taille avec M"
author:
  - name: "Eric Marcon"
    authsuperscript: "1*"
  - name: "Florence Puech"
    authsuperscript: "2"
affiliation:
  - affsuperscript: 1
    dptuniv: "AgroParisTech, UMR AMAP, CIRAD, CNRS, INRAE, IRD, Univ Montpellier, Montpellier, France."
  - affsuperscript: 2
    dptuniv: "Université Paris-Saclay, INRAE, AgroParisTech, Paris-Saclay Applied Economics, F-91120 Palaiseau, France"
corrauthor:
  email: eric.marcon@agroparistech.fr
abstract: >
  Cet article méthodologique porte sur une mesure relative de la concentration spatiale en espace continu, la fonction $M$, proposée par @Marcon2010.
  L'objectif de notre contribution est d'apporter des réponses au traitement de jeu de données spatialisées de grande taille avec M sous R. 
  Plus précisément, les deux sources d'incertitude pour le traitement de jeux de données importants sont analysées: l'estimation des erreurs liées à l'approximation de la position géographique des observations et les délais de calcul. 
  Dans un premier temps, nous testons l'impact de l'approximation de la position géographique sur la précision de M et du temps de calcul associé, comme proposé par @Tidu2023. 
  Dans un second temps, les besoins en temps et en mémoire du calcul exact avec le package dbmss sous R sont évalués. 
  Le code R est fourni pour la reproductibilité des résultats.
date: "`r format(Sys.time(), '%Y %B %d')`"
archive: "`r format(Sys.time(), '%d %B %Y')`"
url: https://EricMarcon.github.io/Mapprox/
github-repo: EricMarcon/Mapprox
# Language
lang: fr-FR
# Bibliography
bibliography: references.bib
biblio-style: chicago
# LaTeX
# Print table of contents in PDFs?
pdftoc: false
# If true, choose its depth
toc-depth: 3
# URL color
urlcolor: blue
# Do not modify
always_allow_html: yes
output:
  bookdown::html_document2:
    base_format: distill::distill_article
    toc: yes
    toc_float: yes
  bookdown::pdf_book:
    template: latex/template.tex
    citation_package: natbib
    latex_engine: xelatex
    keep_tex: no
---

```{r DoNotModify, include=FALSE}
### Utilities. Do not modify.
# Installation of packages if necessary
InstallPackages <- function(Packages) {
  InstallPackage <- function(Package) {
    if (!Package %in% installed.packages()[, 1]) {
      install.packages(Package, repos="https://cran.rstudio.com/")
    }
  }
  invisible(sapply(Packages, FUN = InstallPackage))
}

# Basic packages
InstallPackages(c("bookdown", "formatR", "ragg", "kableExtra"))

# Chunk font size hook: allows size='small' or any valid Latex font size in chunk options
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$size != "normalsize", paste0("\n \\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})
```

```{r Options, include=FALSE}
### Customized options for this document
# Add necessary packages here
Packages <- c("tidyverse", "spatstat", "dbmss", "pbapply", "plyr", "GoFKernel", "microbenchmark", "profmem")
# Install them
InstallPackages(Packages)

# knitr options
knitr::opts_chunk$set(
  cache =   TRUE,     # Cache chunk results
  include = TRUE,     # Show/Hide chunks
  echo =    TRUE,     # Show/Hide code
  warning = FALSE,    # Show/Hide warnings
  message = FALSE,    # Show/Hide messages
  # Figure alignment and size
  fig.align = 'center', out.width = '80%',
  # Graphic devices (ragg_png is better than standard png)
  dev = c("ragg_png", "pdf"),
  # Code chunk format
  tidy = FALSE, tidy.opts = list(blank=FALSE, width.cutoff=50),
  size = "scriptsize", knitr.graphics.auto_pdf = TRUE
  )
options(width = 50)

# ggplot style
library("tidyverse")
theme_set(theme_bw())
theme_update(panel.background=element_rect(fill="transparent", colour=NA),
             plot.background=element_rect(fill="transparent", colour=NA))
knitr::opts_chunk$set(dev.args=list(bg="transparent"))

# Random seed
set.seed(973)
```

# Motivation

L'accès grandissant à d'importants jeux de données individuelles et spatialisées et une plus grande puissance de calcul ont encouragé le développement d'outils d'analyse statistiques permettant de traiter au mieux de telles données [@Baddeley2016a]. 
Des études empiriques à des niveaux géographiques très fins ont ainsi pu été proposées au cours des dernières années pour des jeux de données de grande taille. 
Une attention particulière a porté sur la détection des structures spatiales (attraction, répulsion, indépendance) de données individuelles spatialisées à partir d'analyses ne reposant plus des données zonées mais sur des données géolocalisées. 
Ce type d'approche a l'avantage de préserver les positions exactes des entités analysées  et par conséquent de ne pas gommer les spécificités individuelles. 
Diverses études ont montré toute l'importance de retenir une telle méthodologie dans des domaines très variés comme en géographie [@Sweeney1998, @Deurloo2008], en économie [@Arbia1989, @Marcon2003a], en écologie [@Cressie1993,@Lentz2011],  en biologie [@Dray2021] etc.
Dans un article récent, @Tidu2023 soulignent tout l'intérêt d'une mesure statistique particulière, la fonction M proposée par @Marcon2010. 
Cette mesure, que nous dénommerons *M* dans la suite de l'article, permet de mettre en évidence et les structures spatiales au sein d'une distribution spatialisée (attraction, répulsion, indépendance) à partir d'une étude fondée sur les distances séparant les entités analysées. 
Toutefois, si cette mesure permet de préserver toute la richesse des données individuelles géolocalisées, elle nécessite un temps de calcul plus long que d'autres mesures fondées sur les distances puisqu'elle est à la fois une mesure cumulative et relative (voir @Marcon2012c pour une revue de littérature sur les avantages et les limites d'une dizaine mesures existantes fondées sur les distances). 
@Tidu2023 proposent de limiter les temps de calculs de *M* en introduisant une erreur de positionnement volontaire des entités analysées. 
Ainsi, dans leur étude, les établissements industriels en Sardaigne (Italie) ne sont plus localisés à leur adresse postale exacte mais au centroïde de leur municipalité. 
Ce repositionnement permet de réduire les temps de calcul car le nombre de distances possibles entre les établissements est, de fait, limité aux distances séparant les centroïdes des communes. 
Dans notre article, nous proposons dans un premier temps d'étudier la généralisation de cette méthode d'approximation géographique des localisations des entités analysées.
Ce travail méthodologique reposant sur un nombre d'emplacements des entités volontairement limité permettra de quantifier l'importance de la détérioration de l'information que cette approche crée. 
Dans un second temps, nous montrons les avantages de l'utilisation du package *dbmss* [@Marcon2014] pour effectuer ces approximations.

Le plan de l'article est le suivant. 
Une première section fournit le code nécessaire à la création de jeux de données. 
Des jeux de points de grande taille (de l'ordre de 100 000 points) complètement aléatoires ou (géographiquement) concentrés sont tirés. 
L'approximation de leur position consiste à les rassembler au centre des cases d'une grille, selon l'approche de @Tidu2023 qui les positionnent au centre des unités administratives dans lesquelles ils se trouvent. 
La deuxième section détaille l'utilisation du package *dbmss* pour calculer la fonction *M* et son intervalle de confiance à partir d'un tableau donnant la position et les caractéristiques des points ou bien une matrice de distances entre eux. 
La troisième section teste l'impact de l'approximation des points. 
Enfin, la dernière section mesure la performance de *dbmss* en fonction de la taille du jeu de points.


# Simulation des données

Les jeux de données que nous allons considérer dans cet article sont obtenus par simulation. 
Le code R est donné en annexe, ce qui permet une parfaite reproductibilité les exemples traités (ou d'en développer d'autres).

## Tirage des points

Un jeu de points est tiré par un processus binomial dans une fenêtre carrée de côté 1. 
On associe à chaque point une marque qualitative: "Cas" ou "Contrôle". 
La majorité des points sont des "Contrôles" et une partie constitue des "Cas", dont la structure spatiale est étudiée. 
Le poids des points est tiré dans une loi gamma dont les paramètres de forme et d'échelle sont libres.

```{r}
#| label: ParamsCSR
#| include: false
#| ref.label: ParamsCSRCode
```

Dans notre exemple, 40 000 points sont tirés et un point sur vingt est un Cas.

(ref:Xcsr) Tirage d'un jeu de points complètement aléatoire. Seuls les cas (un point sur 20) sont représentés.

```{r}
#| label: XcsrFig
#| echo: false
#| ref.label: XcsrCode
#| fig.cap: "(ref:Xcsr)"
```

Seuls les points "Cas" sont représentés sur dans la figure  \@ref(fig:XcsrFig). 
La taille des points est une marque quantitative (`Weight`): graphiquement la surface des points est proportionnelle à la taille des points. 
Etant donné le grand nombre de Cas sur la fenêtre, la distribution de la taille de ces points n'est que peu lisible. 
Sa distribution est donnée en figure \@ref(fig:PointSizeFig).

(ref:PointSize) Distribution de la taille des cas.

```{r}
#| label: PointSizeFig
#| include: false
#| ref.label: PointSizeCode
#| fig.cap: "(ref:PointSize)"
```

Dans cet exemple, le tirage des points est complètement aléatoire (*complete spatial randomness*: CSR), c'est-à-dire qu'il n'y a pas ici de simulation d'attraction ou de dispersion de points qui pourraient générer des concentrations spatiales de points (agrégats) ou, au contraire, des régularités spatiales (dispersions).

Des jeux de points agrégés peuvent être tirés dans un processus de @Matern1960.

```{r}
#| label: ParamsMatern
#| include: false
#| ref.label: ParamsMaternCode
```

(ref:XMatern) Tirage d'un jeu de points dont les cas (représentés) sont agrégés. 

```{r}
#| label: XMaternFig
#| echo: false
#| ref.label: XMaternCode
#| fig.cap: "(ref:XMatern)"
```

Les Cas apparaissent dans figure \@ref(fig:XMaternFig): les agrégats sont nettement visibles.
Les contrôles (non représentés) sont distribués complètement aléatoirement.


## Maillage de l'espace

Considérons la simulation des Cas obtenus par le processus de Matérn et découpons la fenêtre en une grille. 
Un maillage est de l'espace précédemment considéré est obtenu, qui permet de simuler l'approximation habituelle de la position des points d'une unité administrative sur la position de son centre.

```{r}
#| label: ParamsPartitions
#| include: false
#| ref.label: ParamsPartitionsCode
```

```{r}
#| label: group_points
#| include: false
#| ref.label: group_pointsCode
```

La position recentrée est présentée sur la carte de la figure \@ref(fig:GroupedFig).
Chaque cellule ne contient plus qu'un seul point de chaque type dont le poids est la somme des poids des points individuels.

(ref:Grouped) Repositionnement des points dans une grille arbitraire. L'absence de Cas dans une cellule est aisément détectable (point unicolore bleu), tout comme la forte présence de Cas dans une cellule (point bicolore mais à dominante rouge).

```{r}
#| label: GroupedFig
#| echo: false
#| ref.label: GroupedCode
#| fig.cap: "(ref:Grouped)"
```


# Calcul de M

```{r}
#| label: Paramsr
#| include: false
#| ref.label: ParamsrCode
```

## Données nécessaires

Dans le package *dbmss*, la fonction s'applique à un jeu de points ou à une matrice de distance.
Un jeu de points dont les Cas sont agrégé selon les paramètres utilisés précédemment est tiré, et la matrice de distances entre toutes les paires de ses points est calculée pour constituer les données sur lesquelles les tests de performance seront réalisés.

```{r}
#| label: DtableM
#| include: false
#| ref.label: DtableMCode
```

## Jeu de points

```{r}
#| label: PointSetM
#| include: false
#| ref.label: PointSetMCode
```

La fonction `Mhat()` du package *dbmss* permet d'estimer la fonction *M*.
La valeur de référence théorique de *M* est 1 car cette fonction rapporte la proportion de Cas jusqu'à une distance $r$ à celle observée sur toute la fenêtre. 
L'agrégation des Cas sera mise en évidence par des valeurs de *M* supérieures à 1 (la présence relative de Cas est plus importante localement que sur l'ensemble de la fenêtre) et la dispersion des Cas par des valeurs inférieures à 1. 
On observe (figure \@ref(fig:MFig)) que *M* détecte une agglomération des Cas, ce qui est en accord avec la simulation de ce type de points (les contrôles ayant localisation complètement aléatoire sur la fenêtre). 
L'avantage d'une fonction fondée sur les distances est nettement visible: elle permet de détecter exactement à quelle(s) distance(s) les phénomènes d'attraction se produisent et sont les plus importants (pour les fonctions dont les valeurs peuvent être comparées à différents rayons, comme *M*).

La fonction `Menvelope()` permet de calculer l'intervalle de confiance global [@Duranton2005] de la valeur de la fonction sous l'hypothèse nulle de localisation aléatoire des points.

(ref:M) Valeur de *M* en fonction de la distance au point de référence. l'intervalle de confiance, simulé à 95%, apparaît en gris et est centré sur la valeur 1.

```{r}
#| label: MFig
#| echo: false
#| ref.label: MCode
#| fig.cap: "(ref:M)"
```


## Matrice de distances

```{r}
#| label: Dtable
#| include: false
#| ref.label: DtableCode
```

Les matrices permettent de traiter des distances non euclidiennes (temps de transport, distance routière...) qui ne peuvent pas être représentées par un jeu de points.

Les fonctions `Mhat()` et `MEnvelope()` sont les mêmes, et fournissent les mêmes résultats quelle que soit la forme des données utilisée ici.


## Performance

Le calcul des distances est extrêmement rapide dans la fonction `Mhat()`: la matrice le fait économiser, mais le traitement complet à partir d'une matrice est finalement plus long (tableau \@ref(tab:MmbTab)).

```{r}
#| label: Mmb
#| include: false
#| ref.label: MmbCode
```

```{r}
#| label: MmbTab
#| echo: false
mb |> summary() |> as.data.frame() |>
  select(expr, median) |> 
  knitr::kable(
    caption = "Temps d'exécution médian de l'estimation de la fonction M, à partir d'un jeu de points ou d'une matrice de distances", 
    longtable = FALSE, 
    booktabs = TRUE
  ) %>%
  kableExtra::kable_styling(bootstrap_options = "striped", full_width = TRUE)
```

# Tests

```{r}
#| label: XtoM
#| include: false
#| ref.label: XtoMCode
```

```{r}
#| label: ParamsSims
#| include: false
#| ref.label: ParamsSimsCode
```

L'effet de l'approximation de la localisation est testé d'abord sur un jeu de points agrégé, similaire aux données réelles de @Tidu2023.
Dans un deuxième temps, le cas d'un jeu de points non structuré est traité.

## Cas d'une distribution agrégée (Matérn)

```{r}
#| label: XMaternList
#| include: false
#| ref.label: XMaternListCode
```

`r simulations_n` jeux de points agrégés sont simulés.
Pour évaluer l'effet de l'approximation de la position, le calcul exact et le calcul sur les points de la grille sont effectués sur chaque jeu de points.

```{r}
#| label: MMaternTime
#| include: false
#| ref.label: MMaternTimeCode
```

Les valeurs moyennes des estimations de *M* sont présentées dans la figure \@ref(fig:MapproxMaternFig).

(ref:MapproxMatern) Estimation moyenne de la fonction *M* à partir de la position exacte des points comparée aux valeurs obtenues en regroupant les points.

```{r}
#| label: MapproxMaternFig
#| echo: false
#| ref.label: MapproxMaternCode
#| fig.cap: "(ref:MapproxMatern)"
```

La corrélation entre les valeurs de $M$ estimées par chaque méthode est calculée à chaque distance (figure \@ref(fig:CorMaternFig)).

(ref:CorMatern) Corrélation entre les valeurs de *M* estimées à partir de la position exacte des points et en regroupant les points.

```{r}
#| label: CorMaternFig
#| echo: false
#| ref.label: CorMaternCode
#| fig.cap: "(ref:CorMatern)"
```

La corrélation est très élevée dès que la distance prise en compte dépasse la maille de la grille.

Les valeurs sont ensuite comparées.
La figure \@ref(fig:CompMaternFig) montre, en rouge, la variabilité de la valeur de $M$ (son coefficient de variation) au cours des simulations.
Par définition, la valeur moyenne est sans erreur.
L'erreur relative (à la valeur exacte de $M$) moyenne est présentée en noir, avec son écart-type normalisé par la valeur exacte de $M$.

(ref:CorMatern) Comparaison des valeurs de *M* estimées à partir de la position exacte des points et en regroupant les points.

```{r}
#| label: CompMaternFig
#| echo: false
#| ref.label: CompMaternCode
#| fig.cap: "(ref:CompMatern)"
```


Bien que les corrélations soient très grandes, l'erreur relative dépasse 25% jusqu'à 2 fois la taille de la maille.


## Cas d'une distribution complètement aléatoire (CSR)

```{r}
#| label: XCSRList
#| include: false
#| ref.label: XCSRListCode
```

Les mêmes simulations sont effectuées avec un jeu de points complètement aléatoire.
Le calcul exact et le calcul sur les points de la grille sont effectués sur chaque jeu de points.

```{r}
#| label: MCSRTime
#| include: false
#| ref.label: MCSRTimeCode
```

Les valeurs moyennes sont présentées dans la figure \@ref(fig:MapproxCSRFig).

(ref:MapproxCSR) Estimation moyenne de la fonction *M* à partir de la position exacte des points comparée aux valeurs obtenues en regroupant les points.

```{r}
#| label: MapproxCSRFig
#| echo: false
#| ref.label: MapproxCSRCode
#| fig.cap: "(ref:MapproxCSR)"
```

(ref:CorCSR) Corrélation entre les valeurs de *M* estimées à partir de la position exacte des points et en regroupant les points.

```{r}
#| label: CorCSRFig
#| echo: false
#| ref.label: CorCSRCode
#| fig.cap: "(ref:CorCSR)"
```

En absence de structure spatiale, les corrélations sont bien plus faibles (figure \@ref(fig:CorCSRFig)).

(ref:CompCSR) Comparaison des valeurs de *M* estimées à partir de la position exacte des points et en regroupant les points.

```{r}
#| label: CompCSRFig
#| echo: false
#| ref.label: CompCSRCode
#| fig.cap: "(ref:CompCSR)"
```

La valeur moyenne de $M$ est 1 à toutes les distances par construction: les cas et les contrôles sont distribués complètement aléatoirement.

Les barres rouges sur la figure \@ref(fig:CompCSRFig) représentent l'écart-type empirique de la valeur de $M$, calculé à partir des simulations.
Les points noirs montrent l'erreur apportée par l'approximation, mesurée par l'écart moyen entre les valeurs de $M$ calculées avec ou sans approximation.
Les barres d'erreur sont l'écart-type de cette différence.

On constate que l'approximation sous-estime systématiquement $M$.
L'erreur est maximale jusqu'à la taille de la grille: tous les points d'une même cellule sont placés artificiellement en son centre.
Elle chute brutalement au-delà de ce seuil mais reste importante jusqu'à 4 fois la taille de la grille.

Notre conclusion prudente dans ce cas est que l'approximation de doit pas être utilisée pour étudier les interactions à courte distance.

Le test sur les corrélations effectué ici est beaucoup plus sévère que dans @Tidu2023: les points n'ont aucune structure, donc $M$ permet de détecter les petites variations aléatoires des différents tirages.
En présence d'une structure spatiale, les valeurs de $M$ sont nettement mieux corrélées, mais dans tous les cas l'erreur d'estimation est grande.

# Performance de M

## Temps de calcul

Le temps de calcul nécessaire au calcul exact est évalué pour une gamme de nombres de points (figure \@ref(fig:TestTimeFig)).

```{r}
#| label: ParamsXSize
#| include: false
#| ref.label: ParamsXSizeCode
```

(ref:TestTime) Temps de calcul de l'estimation de la fonction *M* en fonction de la taille du jeu de points.

```{r}
#| label: TestTimeFig
#| echo: false
#| ref.label: TestTimeCode
#| fig.cap: "(ref:TestTime)"
```


Le temps de calcul est lié à la taille du jeu de points par une loi puissance.

```{r}
#| label: TimeModel
#| include: false
#| ref.label: TimeModelCode
```

Il augmente moins vite que le carré du nombre de points.
Il peut être estimé très précisément ($R^2=$ `r format(summary(M_time_lm)$r.squared, digits=2)`) par la relation $t = t_0 (n / n_o)^p$ où $t$ est le temps estimé pour $n$ points connaissant le temps $t_0$ (ex.: `r format(as.numeric(M_time[5, 2]), digits=3)`) pour $n_0$ points (ex.: `r as.integer(M_time[5, 1])`) et $p$ la relation de puissance (`r format(M_time_lm$coefficients[2], digits=3)`).

## Mémoire

La mémoire utilisée est évaluée pour les mêmes tailles de données (figure \@ref(fig:TestMemFig)).

(ref:TestMem) Mémoire nécessaire pour l'estimation de la fonction *M* en fonction de la taille du jeu de points.

```{r}
#| label: TestMemFig
#| echo: false
#| ref.label: TestMemCode
#| fig.cap: "(ref:TestMem)"
```

La mémoire nécessaire (en Mo) augmente linéairement avec le nombre de points et n'est jamais critique pour des tailles de jeux de points traitables dans des temps raisonnables.
Cela permet de relativiser la conclusion de @Tidu2023 sur la puissance et le temps de calculs nécessaires en utilisant *M* sur des jeux de données de taille importante.

La mémoire utilisée par les objets `Dtable` pour le calcul de $M$ à partir d'une matrice de distance est bien supérieure: c'est celle d'une matrice numérique, de l'ordre de 8 octets fois le nombre de points au carré, soit 800 Mo pour 10000 points seulement.


# Conclusion

Le temps de calcul de $M$ est de l'ordre de 6 secondes pour un jeu de 100 000 points sur un ordinateur portable (processeur Intel i7-1360P 2.20 GHz), et nécessite 25 Mo de RAM.
Le calcul d'un intervalle de confiance à partir de 1000 simulations prend donc moins de deux heures.

Pour un jeu de cinq millions de points, le temps de calcul attendu est $6 \times 50^{1.8} = 6860$ secondes, près de deux heures.
1000 simulations nécessiteraient alors environ trois mois.
Le calcul des distances est parallélisé: un serveur de calcul augmenterait drastiquement la performance mais au prix d'une complexité de mise en oeuvre qui limite son usage.

En se limitant à la puissance de calcul d'un ordinateur personnel, le calcul exact se justifie donc pleinement pour des données de l'ordre de $10^5$ points: quelques heures suffisent à calculer des intervalles de confiance.

Au-delà, l'approximation de la localisation permet de ramener la taille du jeu de points à celle du nombre de localisations retenues.
Le prix à payer est l'absence d'information à l'échelle des unités géographiques élémentaires (les cellules de la grille ici), et une erreur relative importante.
Si les valeurs de $M$ sont utilisées comme covariables dans un modèle (par exemple pour expliquer la croissance des points), alors cette imprécision est acceptable parce que la corrélation entre leur valeur exacte et leur valeur approximée est élevée, dès que les points présentent une structure spatiale.


# Annexe

Le code utilisé dans cet article est détaillé ici.

## Simulation des données

### Tirage des points

Un jeu de points est tiré aléatoirement avec les paramètres suivants:

-   le nombre de points,
-   la proportion de contrôles,
-   la forme et l'échelle de la loi gamma.

```{r}
#| label: ParamsCSRCode
#| eval: false
par_points_nb <- 40000
par_case_ratio <- 1/20
par_size_gamma_shape <- 0.95
par_size_gamma_scale  <- 10
```

La fonction `X_csr()` permet de tirer un semis de points selon des paramètres déterminés.
L'argument `points_nb` qui fixe le nombre de points peut être modifié; les autres paramètres ont leur valeur fixée plus haut.

```{r}
#| label: XcsrCode
#| eval: false
library("tidyverse")
library("spatstat")
library("dbmss")
X_csr <- function(
    points_nb,
    case_ratio = par_case_ratio,
    size_gamma_shape = par_size_gamma_shape,
    size_gamma_scale = par_size_gamma_scale) {
  points_nb %>% 
    runifpoint() %>% 
    as.wmppp() ->
    X
  cases_nb <- round(points_nb *  case_ratio)
  controls_nb <- points_nb - cases_nb
  c(rep("Control", controls_nb), rep("Case", cases_nb)) %>% 
    as.factor() ->
    X$marks$PointType
  rgamma(
    X$n, 
    shape = size_gamma_shape, 
    scale = size_gamma_scale
  ) %>% 
    ceiling() ->
    X$marks$PointWeight
  X
}

# Example
X <- X_csr(par_points_nb)
# Map the cases
autoplot(X[X$marks$PointType == "Case"])
```


La distribution des tailles est donnée par l'histogramme suivant:

```{r}
#| label: PointSizeCode
#| eval: false
# Point size distribution
hist(
  X$marks$PointWeight, 
  breaks = unique(X$marks$PointWeight), 
  main = "",
  xlab = "Point size"
)
```

La fonction `X_matern()` permet de tirer un semis de points dont les Cas sont concentrés par un processus de @Matern1960.
Les paramètres sont:

-   $\kappa$: le nombre d'agrégats attendu,
-   `scale`: leur rayon.

```{r}
#| label: ParamsMaternCode
#| eval: false
# Expected number of clusters
par_kappa <- 20
# Cluster radius
par_scale <-  0.1
```

Le code de la fonction est le suivant:

```{r}
#| label: XMaternCode
#| eval: false
X_matern <- function(
    points_nb,
    case_ratio = par_case_ratio,
    kappa = par_kappa,
    scale = par_scale,
    size_gamma_shape = par_size_gamma_shape,
    size_gamma_scale = par_size_gamma_scale) {
  cases_nb <- round(points_nb *  case_ratio)
  controls_nb <- points_nb - cases_nb
  # CSR controls
  controls_nb %>% 
    runifpoint() %>% 
    superimpose(
      # Matern cases
      rMatClust(
        kappa = kappa, 
        scale = scale, 
        mu = cases_nb / kappa
      ) 
    ) %>% 
    as.wmppp() ->
    X
  # Update the number of cases
  cases_nb <- X$n - controls_nb
  c(rep("Control", controls_nb), rep("Case", cases_nb)) %>% 
    as.factor() ->
    X$marks$PointType
  rgamma(
    X$n, 
    shape = size_gamma_shape, 
    scale = size_gamma_scale
  ) %>% 
    ceiling() ->
    X$marks$PointWeight
  X
}

# Example
X <- X_matern(par_points_nb)
# Map the cases
autoplot(X[X$marks$PointType == "Case"])
```


### Maillage de l'espace

Le nombre de lignes et de colonnes est paramétré:

```{r}
#| label: ParamsPartitionsCode
#| eval: false
# Number of rows and columns
par_partitions <- 20
```

La fonction `group_points()` rassemble au centre de chaque cellule de la grille tous les points qu'elle contient.
Cela permet de simuler l'approximation habituelle de la position des points d'une unité administrative sur la position de son centre.

```{r}
#| label: group_pointsCode
#| eval: false
# Group points into cells
group_points <- function(X, partitions = par_partitions) {
X %>%
  with(tibble(
    x, 
    y, 
    PointType = marks$PointType, 
    PointWeight = marks$PointWeight)
  ) %>% 
  mutate(
    x_cell = ceiling(x * partitions) / partitions - 1 / 2 / partitions,
    y_cell = ceiling(y * partitions) / partitions - 1 / 2 / partitions
  ) %>%
  group_by(PointType, x_cell, y_cell) %>% 
  summarise(n = n(), PointWeight = sum(PointWeight)) %>% 
  rename(x = x_cell, y = y_cell) %>% 
  as.wmppp(window = X$window, unitname = X$window$units)
}
```

La figure est obtenue par le code suivant:
```{r}
#| label: GroupedCode
#| eval: false
group_points(X) %>% autoplot(alpha = 0.5)
```


## Calcul de M

Les distances auxquelles la fonction *M* est calculées sont choisies dans `r`.

```{r}
#| label: ParamsrCode
#| eval: false
r <- c((0:9) / 100, (2:10) / 20)
```

### Données nécessaires

Dans le package *dbmss*, la fonction s'applique à un jeu de points, objet de classe `wmppp`, ou à une matrice de distance, objet de classe `Dtable`.

Nous partons d'un tableau (data.frame) contenant les colonnes `x`, `y`, `PointType` et `PointWeight`.

Les coordonnées spatiales des points sont données par les colonnes `x` et `y`. 
Aucune grille n'est considérée dans un premier temps.

```{r}
#| label: DtableMCode
#| eval: true
# Draw 10000 points and make a dataframe
X_matern(points_nb = 1E4) %>% 
  with(data.frame(x, y, marks)) ->
  points_df
head(points_df)
```

### Jeu de points

La fonction `wmppp()` permet de créer le jeu de points à partir du tableau.
La fenêtre est créée automatiquement si elle n'est pas précisée.
Ici, c'est un carré de côté 1.

```{r}
#| label: PointSetMCode
#| eval: true
library("dbmss")
X <- wmppp(points_df, window = square(1))
autoplot(X)
```

La fonction `Mhat()` permet d'estimer la valeur de la fonction *M*.

```{r}
#| label: Mhat
#| eval: true
X %>% 
  Mhat(r = r, ReferenceType = "Case") %>% 
  autoplot()
```

La fonction `Menvelope()` permet de calculer l'intervalle de confiance de la valeur de la fonction sous l'hypothèse nulle de localisation aléatoire des points.
L'intervalle de confiance global [@Duranton2005] est calculé en précisant l'argument `Global = TRUE`.

```{r}
#| label: MCode
#| eval: true
X %>% 
  MEnvelope(r = r, ReferenceType = "Case", Global = TRUE) %>% 
  autoplot()
```

### Matrice de distances

La fonction `as.Dtable()` permet de créer un objet `Dtable`.

```{r}
#| label: DtableCode
#| eval: false
d_matrix <- as.Dtable(points_df)
```

Il peut aussi être créé à partir d'une matrice de distances obtenue autrement, contenant par exemple des distances non euclidiennes (temps de transport, distance routière...).

```{r}
#| label: Dtable2
#| eval: true
# A Dtable containing two points
Dmatrix <- matrix(c(0, 1, 1, 0), nrow = 2)
PointType <- c("Type1", "Type2")
PointWeight <- c(2, 3)
Dtable(Dmatrix, PointType, PointWeight)
```

Les fonctions `Mhat()` et `MEnvelope()` sont les mêmes que pour les jeux de points.

```{r}
#| label: Mid
#| eval: true
identical(
  Mhat(X, r = r, ReferenceType = "Case", NeighborType = "Control"),
  Mhat(d_matrix, r = r, ReferenceType = "Case", NeighborType = "Control")
)
```

```{r}
#| label: MEnvelopeid
#| eval: true
d_matrix %>% 
  MEnvelope(r = r, ReferenceType = "Case", Global = TRUE) %>% 
  autoplot()
```


### Performance

Le package *microbenchmark* proposé par @Mersmann2023 est retenu pour chronométrer le temps d'exécution de la fonction *M*.
Le calcul des distances est extrêmement rapide dans la fonction `Mhat()`: la matrice le fait économiser, mais le traitement complet à partir d'une matrice est finalement plus long.

```{r}
#| label: MmbCode
#| eval: true
library("microbenchmark")
mb <- microbenchmark(
  Mhat(X, r = r, ReferenceType = "Case", NeighborType = "Control"),
  Mhat(d_matrix, r = r, ReferenceType = "Case", NeighborType = "Control"),
  times = 4L
)
```

## Tests

La fonction `X_to_M()` calcule la fonction $M$ et renvoie le vecteur de ses valeurs pour chaque distance.
Elle est utile pour mesurer les temps d'exécution.

```{r}
#| label: XtoMCode
#| eval: false
# Compute M
X_to_M <- function(X) {
  X %>% 
    Mhat(r = r, ReferenceType = "Case") %>% 
    pull("M")
}
```

Le nombre de répétition des tests est fixé par `simulations_n`.

```{r}
#| label: ParamsSimsCode
#| eval: false
simulations_n <- 10
```

### Cas d'une distribution agrégée (Matérn)

`X_matern_list` contient `simulations_n` tirages du jeu de points.
`X_matern_grouped_list` contient les mêmes simulations, dont les points ont été regroupés dans les cases de la grille.

```{r}
#| label: XMaternListCode
#| eval: false
# Simulate X
X_matern_list <- replicate(
  simulations_n, 
  expr = X_matern(par_points_nb), 
  simplify = FALSE
)
# Group points and compute M
X_matern_grouped_list <- lapply(
  X_matern_list, 
  FUN = group_points, 
  partitions = par_partitions
)
```

Pour évaluer l'effet de l'approximation de la position, le calcul exact et le calcul sur les points de la grille sont effectués sur chaque jeu de points.

```{r}
#| label: MMaternTimeCode
#| eval: true
library("pbapply")
# Compute M
system.time(M_matern_original <- pbsapply(X_matern_list, FUN = X_to_M))
system.time(M_matern_grouped <- sapply(X_matern_grouped_list, FUN = X_to_M))
```

Le calcul approximé est très rapide parce qu'il réduit le nombre de points à celui du nombre de cellules.

Les valeurs moyennes des estimations de *M* sont présentées ci-dessous.

```{r}
#| label: MapproxMaternCode
#| eval: true
tibble(
  r,
  Original = rowMeans(M_matern_original), 
  Grouped =  rowMeans(M_matern_grouped)
) %>% 
  pivot_longer(
    cols = !r,
    names_to = "M", 
    values_to = "value"
  ) %>% 
  ggplot(aes(x = r, y = value, color = M)) +
  geom_line() +
  geom_point()
```

La corrélation entre les valeurs de $M$ estimées par chaque méthode est calculée à chaque distance.

```{r}
#| label: CorMaternCode
#| eval: true
# Correlation
M_cor <- function(r_value, M_original, M_grouped) {
  r_index <- which(r == r_value)
  # Return
  c(
    # Distance
    r_value,
    # Correlation
    cor(M_original[r_index, ], M_grouped[r_index, ])
  ) 
}
sapply(
  r, 
  FUN = M_cor, 
  M_original = M_matern_original, 
  M_grouped = M_matern_grouped
) %>%
  t() %>% 
  as_tibble() %>% 
  rename(r = V1, correlation = V2) %>% 
  ggplot(aes(x = r, y = correlation)) +
    geom_point() +
    geom_line()
```

La corrélation est très élevée dès que la distance prise en compte dépasse la maille de la grille.
Les valeurs sont ensuite comparées.

```{r}
#| label: CompMaternCode
#| eval: true
# Compare values
M_bias <- function(r_value, M_original, M_grouped) {
  r_index <- which(r == r_value)
  # Return
  c(
    # Distance
    r_value,
    # Relative error
    mean((M_grouped[r_index, ] - M_original[r_index, ]) / M_original[r_index, ]),
    # Standardised error sd
    sd(M_grouped[r_index, ] - M_original[r_index, ]) / mean(M_grouped[r_index, ]), 
    # Coefficient of variation
    sd(M_original[r_index, ] / mean(M_original[r_index, ]))
  )
}
sapply(
  r, 
  FUN = M_bias, 
  M_original = M_matern_original, 
  M_grouped = M_matern_grouped
) %>% 
  t() %>% 
  as_tibble() %>% 
  rename(r = V1, `Relative error` = V2, `Error CV` = V3, `M CV` = V4) %>% 
  ggplot() +
    geom_point(aes(x = r, y = `Relative error`)) +
    geom_errorbar(
      aes(
        x = r, 
        ymin = `Relative error` - `Error CV`, 
        ymax = `Relative error` + `Error CV`
      )
    ) +
    geom_errorbar(aes(x = r, ymin = -`M CV`, ymax = `M CV`), col = "red")
```


### Cas d'une distribution complètement aléatoire (CSR)

`X_csr_list` contient `simulations_n` tirages du jeu de points.

```{r}
#| label: XCSRListCode
#| eval: false
# Simulate X
X_csr_list <- replicate(
  simulations_n, 
  expr = X_csr(par_points_nb), 
  simplify = FALSE
)
# Group points and compute M
X_csr_grouped_list <- lapply(
  X_csr_list, 
  FUN = group_points, 
  partitions = par_partitions
)
```

Le calcul exact et le calcul sur les points de la grille sont effectués sur chaque jeu de points.

```{r}
#| label: MCSRTimeCode
#| eval: true
# Compute M
system.time(M_csr_original <- pbsapply(X_csr_list, FUN = X_to_M))
system.time(M_csr_grouped <- sapply(X_csr_grouped_list, FUN = X_to_M))
```

Les valeurs moyennes sont présentées ci-dessous.

```{r}
#| label: MapproxCSRCode
#| eval: true
tibble(
  r,
  Original = rowMeans(M_csr_original), 
  Grouped =  rowMeans(M_csr_grouped)
) %>% 
  pivot_longer(
    cols = !r,
    names_to = "M", 
    values_to = "value"
  ) %>% 
  ggplot(aes(x = r, y = value, color = M)) +
  geom_line() +
  geom_point()
```

La corrélation entre les valeurs de $M$ calculées par chaque méthode est calculée à chaque distance.

```{r}
#| label: CorCSRCode
#| eval: true
# Correlation
sapply(
  r, 
  FUN = M_cor, 
  M_original = M_csr_original, 
  M_grouped = M_csr_grouped
) %>%
  t() %>% 
  as_tibble() %>% 
  rename(r = V1, correlation = V2) %>% 
  ggplot(aes(x = r, y = correlation)) +
    geom_point() +
    geom_line()
```

En absence de structure spatiale, les corrélations sont bien plus faibles.

Les valeurs sont comparées.

```{r}
#| label: CompCSRCode
#| eval: true
# Compare values
sapply(
  r, FUN = M_bias, 
  M_original = M_csr_original, 
  M_grouped = M_csr_grouped
) %>% 
  t() %>% 
  as_tibble() %>% 
  rename(r = V1, `Relative error` = V2, `Error CV` = V3, `M CV` = V4) %>% 
  ggplot() +
    geom_point(aes(x = r, y = `Relative error`)) +
    geom_errorbar(
      aes(
        x = r, 
        ymin = `Relative error` - `Error CV`, 
        ymax = `Relative error` + `Error CV`
      )
    ) +
    geom_errorbar(aes(x = r, ymin = -`M CV`, ymax = `M CV`), col = "red")
```


## Performance de M

### Temps de calcul

Le temps nécessaire au calcul exact est évalué pour une gamme de nombres de points précisée dans `X_sizes`.

```{r}
#| label: ParamsXSizeCode
#| eval: false
X_sizes <- c(1000, 5000) #, 10000, 50000, 100000)
```

La fonction `test_time()` permet de mesurer le temps d'exécution d'une évaluation de la fonction $M$.

```{r}
#| label: TestTimeCode
#| eval: false
library("microbenchmark")
test_time <- function(points_nb) {
  X <- X_csr(points_nb)
  microbenchmark(X_to_M(X), times = 4L) %>% 
    pull("time")
}

X_sizes %>% 
  sapply(FUN = test_time) %>% 
  as_tibble() %>% 
  pivot_longer(cols = everything()) %>% 
  rename(Size = name) %>% 
  group_by(Size) %>% 
  summarise(Time = mean(value) / 1E9, sd = sd(value) / 1E9) %>% 
  mutate(
    Size = as.double(
      plyr::mapvalues(
        .$Size, 
        from = paste0("V", seq_along(X_sizes)), 
        to = X_sizes
      )
    )
  ) -> M_time
M_time %>% 
  ggplot(aes(x = Size, y = Time)) +
    geom_point() +
    geom_errorbar(aes(ymin = Time - sd, ymax = Time + sd)) +
    scale_x_log10() +
    scale_y_log10()
```

Le temps de calcul est lié à la taille du jeu de points par une loi puissance.

```{r}
#| label: TimeModelCode
#| eval: false
# Model
M_time %>% 
  mutate(logTime = log(Time), logSize = log(Size)) ->
  M_time_log
M_time_lm <- lm(logTime ~ logSize, data = M_time_log) 
summary(M_time_lm)
```

## Mémoire

La mémoire utilisée est évaluée avec le package *profmem*.

```{r}
#| label: TestMemCode
#| eval: false
# RAM
library("profmem")
test_ram <-function(points_nb) {
  X <- X_csr(points_nb)
  profmem(X_to_M(X)) %>% 
    pull("bytes") %>% 
    sum()
}
sapply(X_sizes, FUN = test_ram) %>% 
  tibble(Size = X_sizes, RAM = . / 2^20) ->
  M_ram
M_ram %>% 
  ggplot(aes(x = Size, y = RAM)) +
    geom_point() +
    geom_line()
```

La mémoire nécessaire (en Mo) augmente linéairement avec le nombre de points.

```{r}
#| label: MemModelCode
#| eval: false
# Model
lm(RAM ~ Size, data = M_ram) |> summary()
```

